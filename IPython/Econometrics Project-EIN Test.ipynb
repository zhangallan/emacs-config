{
 "metadata": {
  "name": "",
  "signature": "sha256:9e19498dcf425a9459e0b931ce664aadf2289f7cce6168eec53f01af7ae17bf4"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import csv\n",
      "import numpy as np\n",
      "import scipy\n",
      "from pandas import Series, DataFrame\n",
      "import statsmodels.api as sm\n",
      "import statsmodels.formula.api as smf\n",
      "from statsmodels.iolib.summary2 import summary_col # For summarizing\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.dates as mdates\n",
      "import os\n",
      "import datetime as dt"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    # This and the next cell are only here because I needed to hack the source code of statsmodels to get it to return the regression coefficient\n",
      "from scipy import stats, signal\n",
      "from statsmodels.regression.linear_model import OLS, yule_walker\n",
      "from statsmodels.tools.tools import add_constant\n",
      "from statsmodels.tsa.tsatools import lagmat, lagmat2ds, add_trend\n",
      "from statsmodels.tsa.adfvalues import mackinnonp, mackinnoncrit"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# See comment in previous cell\n",
      "class ResultsStore(object):\n",
      "    def __str__(self):\n",
      "        return self._str  # pylint: disable=E1101\n",
      "\n",
      "def _autolag(mod, endog, exog, startlag, maxlag, method, modargs=(),\n",
      "        fitargs=(), regresults=False):\n",
      "    \"\"\"\n",
      "    Returns the results for the lag length that maximimizes the info criterion.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    mod : Model class\n",
      "        Model estimator class.\n",
      "    modargs : tuple\n",
      "        args to pass to model.  See notes.\n",
      "    fitargs : tuple\n",
      "        args to pass to fit.  See notes.\n",
      "    lagstart : int\n",
      "        The first zero-indexed column to hold a lag.  See Notes.\n",
      "    maxlag : int\n",
      "        The highest lag order for lag length selection.\n",
      "    method : str {\"aic\",\"bic\",\"t-stat\"}\n",
      "        aic - Akaike Information Criterion\n",
      "        bic - Bayes Information Criterion\n",
      "        t-stat - Based on last lag\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    icbest : float\n",
      "        Best information criteria.\n",
      "    bestlag : int\n",
      "        The lag length that maximizes the information criterion.\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Does estimation like mod(endog, exog[:,:i], *modargs).fit(*fitargs)\n",
      "    where i goes from lagstart to lagstart+maxlag+1.  Therefore, lags are\n",
      "    assumed to be in contiguous columns from low to high lag length with\n",
      "    the highest lag in the last column.\n",
      "    \"\"\"\n",
      "    #TODO: can tcol be replaced by maxlag + 2?\n",
      "    #TODO: This could be changed to laggedRHS and exog keyword arguments if\n",
      "    #    this will be more general.\n",
      "\n",
      "    results = {}\n",
      "    method = method.lower()\n",
      "    for lag in range(startlag, startlag+maxlag+1):\n",
      "        mod_instance = mod(endog, exog[:,:lag], *modargs)\n",
      "        results[lag] = mod_instance.fit()\n",
      "\n",
      "    if method == \"aic\":\n",
      "        icbest, bestlag = min((v.aic,k) for k,v in results.iteritems())\n",
      "    elif method == \"bic\":\n",
      "        icbest, bestlag = min((v.bic,k) for k,v in results.iteritems())\n",
      "    elif method == \"t-stat\":\n",
      "        lags = sorted(results.keys())[::-1]\n",
      "        #stop = stats.norm.ppf(.95)\n",
      "        stop = 1.6448536269514722\n",
      "        for lag in range(startlag + maxlag, startlag - 1, -1):\n",
      "            icbest = np.abs(results[lag].tvalues[-1])\n",
      "            if np.abs(icbest) >= stop:\n",
      "                bestlag = lag\n",
      "                icbest = icbest\n",
      "                break\n",
      "    else:\n",
      "        raise ValueError(\"Information Criterion %s not understood.\") % method\n",
      "\n",
      "    if not regresults:\n",
      "        return icbest, bestlag\n",
      "    else:\n",
      "        return icbest, bestlag, results\n",
      "\n",
      "def adfuller_edit(x, maxlag=None, regression=\"c\", autolag='AIC',\n",
      "    store=False, regresults=False):\n",
      "    \"\"\"Augmented Dickey-Fuller unit root test\n",
      "\n",
      "    The Augmented Dickey-Fuller test can be used to test for a unit root in a\n",
      "    univariate process in the presence of serial correlation.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like, 1d\n",
      "        data series\n",
      "    maxlag : int\n",
      "        Maximum lag which is included in test, default 12*(nobs/100)^{1/4}\n",
      "    regression : str {'c','ct','ctt','nc'}\n",
      "        Constant and trend order to include in regression\n",
      "        * 'c' : constant only\n",
      "        * 'ct' : constant and trend\n",
      "        * 'ctt' : constant, and linear and quadratic trend\n",
      "        * 'nc' : no constant, no trend\n",
      "    autolag : {'AIC', 'BIC', 't-stat', None}\n",
      "        * if None, then maxlag lags are used\n",
      "        * if 'AIC' or 'BIC', then the number of lags is chosen to minimize the\n",
      "          corresponding information criterium\n",
      "        * 't-stat' based choice of maxlag.  Starts with maxlag and drops a\n",
      "          lag until the t-statistic on the last lag length is significant at\n",
      "          the 95 % level.\n",
      "    store : bool\n",
      "        If True, then a result instance is returned additionally to\n",
      "        the adf statistic\n",
      "    regresults : bool\n",
      "        If True, the full regression results are returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    adf : float\n",
      "        Test statistic\n",
      "    pvalue : float\n",
      "        MacKinnon's approximate p-value based on MacKinnon (1994)\n",
      "    usedlag : int\n",
      "        Number of lags used.\n",
      "    nobs : int\n",
      "        Number of observations used for the ADF regression and calculation of\n",
      "        the critical values.\n",
      "    critical values : dict\n",
      "        Critical values for the test statistic at the 1 %, 5 %, and 10 % levels.\n",
      "        Based on MacKinnon (2010)\n",
      "    icbest : float\n",
      "        The maximized information criterion if autolag is not None.\n",
      "    regresults : RegressionResults instance\n",
      "        The\n",
      "    resstore : (optional) instance of ResultStore\n",
      "        an instance of a dummy class with results attached as attributes\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The null hypothesis of the Augmented Dickey-Fuller is that there is a unit\n",
      "    root, with the alternative that there is no unit root. If the pvalue is\n",
      "    above a critical size, then we cannot reject that there is a unit root.\n",
      "\n",
      "    The p-values are obtained through regression surface approximation from\n",
      "    MacKinnon 1994, but using the updated 2010 tables.\n",
      "    If the p-value is close to significant, then the critical values should be\n",
      "    used to judge whether to accept or reject the null.\n",
      "\n",
      "    The autolag option and maxlag for it are described in Greene.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    see example script\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    Greene\n",
      "    Hamilton\n",
      "\n",
      "\n",
      "    P-Values (regression surface approximation)\n",
      "    MacKinnon, J.G. 1994.  Approximate asymptotic distribution functions for\n",
      "    unit-root and cointegration tests.  `Journal of Business and Economic\n",
      "    Statistics` 12, 167-76.\n",
      "\n",
      "    Critical values\n",
      "    MacKinnon, J.G. 2010. \"Critical Values for Cointegration Tests.\"  Queen's\n",
      "    University, Dept of Economics, Working Papers.  Available at\n",
      "    http://ideas.repec.org/p/qed/wpaper/1227.html\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    if regresults:\n",
      "        store = True\n",
      "\n",
      "    trenddict = {None:'nc', 0:'c', 1:'ct', 2:'ctt'}\n",
      "    if regression is None or isinstance(regression, int):\n",
      "        regression = trenddict[regression]\n",
      "    regression = regression.lower()\n",
      "    if regression not in ['c','nc','ct','ctt']:\n",
      "        raise ValueError(\"regression option %s not understood\") % regression\n",
      "    x = np.asarray(x)\n",
      "    nobs = x.shape[0]\n",
      "\n",
      "    if maxlag is None:\n",
      "        #from Greene referencing Schwert 1989\n",
      "        maxlag = int(np.ceil(12. * np.power(nobs/100., 1/4.)))\n",
      "\n",
      "    xdiff = np.diff(x)\n",
      "    xdall = lagmat(xdiff[:,None], maxlag, trim='both', original='in')\n",
      "    nobs = xdall.shape[0]  # pylint: disable=E1103\n",
      "\n",
      "    xdall[:,0] = x[-nobs-1:-1] # replace 0 xdiff with level of x\n",
      "    xdshort = xdiff[-nobs:]\n",
      "\n",
      "    if store:\n",
      "        resstore = ResultsStore()\n",
      "    if autolag:\n",
      "        if regression != 'nc':\n",
      "            fullRHS = add_trend(xdall, regression, prepend=True)\n",
      "        else:\n",
      "            fullRHS = xdall\n",
      "        startlag = fullRHS.shape[1] - xdall.shape[1] + 1 # 1 for level  # pylint: disable=E1103\n",
      "        #search for lag length with smallest information criteria\n",
      "        #Note: use the same number of observations to have comparable IC\n",
      "        #aic and bic: smaller is better\n",
      "\n",
      "        if not regresults:\n",
      "            icbest, bestlag = _autolag(OLS, xdshort, fullRHS, startlag,\n",
      "                                       maxlag, autolag)\n",
      "        else:\n",
      "            icbest, bestlag, alres = _autolag(OLS, xdshort, fullRHS, startlag,\n",
      "                                        maxlag, autolag, regresults=regresults)\n",
      "            resstore.autolag_results = alres\n",
      "\n",
      "        bestlag -= startlag  #convert to lag not column index\n",
      "\n",
      "        #rerun ols with best autolag\n",
      "        xdall = lagmat(xdiff[:,None], bestlag, trim='both', original='in')\n",
      "        nobs = xdall.shape[0]   # pylint: disable=E1103\n",
      "        xdall[:,0] = x[-nobs-1:-1] # replace 0 xdiff with level of x\n",
      "        xdshort = xdiff[-nobs:]\n",
      "        usedlag = bestlag\n",
      "    else:\n",
      "        usedlag = maxlag\n",
      "        icbest = None\n",
      "    if regression != 'nc':\n",
      "        resols = OLS(xdshort, add_trend(xdall[:,:usedlag+1], regression)).fit()\n",
      "    else:\n",
      "        resols = OLS(xdshort, xdall[:,:usedlag+1]).fit()\n",
      "\n",
      "    adfstat = resols.tvalues[0]\n",
      "#    adfstat = (resols.params[0]-1.0)/resols.bse[0]\n",
      "    # the \"asymptotically correct\" z statistic is obtained as\n",
      "    # nobs/(1-np.sum(resols.params[1:-(trendorder+1)])) (resols.params[0] - 1)\n",
      "    # I think this is the statistic that is used for series that are integrated\n",
      "    # for orders higher than I(1), ie., not ADF but cointegration tests.\n",
      "\n",
      "    # Get approx p-value and critical values\n",
      "    pvalue = mackinnonp(adfstat, regression=regression, N=1)\n",
      "    critvalues = mackinnoncrit(N=1, regression=regression, nobs=nobs)\n",
      "    critvalues = {\"1%\" : critvalues[0], \"5%\" : critvalues[1],\n",
      "            \"10%\" : critvalues[2]}\n",
      "    if store:\n",
      "        resstore.ols = resols\n",
      "        resstore.usedlag = usedlag\n",
      "        resstore.nobs = nobs\n",
      "        return adfstat, pvalue, critvalues, resstore\n",
      "    else:\n",
      "        if not autolag:\n",
      "            return adfstat, pvalue, usedlag, nobs, critvalues\n",
      "        else:\n",
      "            return adfstat, pvalue, usedlag, nobs, critvalues, icbest"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function to calculate the Lewis and Linzer thing\n",
      "\n",
      "# Takes in a dataframe, a varlist with your regression variables, and the SE from your first regression\n",
      "def LewisLinzerWeights(data, varlist, SE):\n",
      "    # Just makes a list of the data for all the independent variables\n",
      "    l = []\n",
      "    for v in varlist[1:]:\n",
      "        l.append(data[v])\n",
      "\n",
      "    # Gets the transpose of the matrix of independent variables\n",
      "    # Note that X_T = X' in the regression equation\n",
      "    X_T = np.matrix([np.ones(len(data[varlist[0]]))] + l)\n",
      "\n",
      "    # Gets the nxn matrix of weights squared\n",
      "    weights_matrix = np.diag(data[\"SE\"]**2)\n",
      "\n",
      "    # Gets the trace matrix in the last part of the equation\n",
      "    matrix_trace = np.trace( np.linalg.inv(X_T * X_T.T) * X_T * weights_matrix * X_T.T )\n",
      "\n",
      "    # Gets the sum of the square of the weights\n",
      "    sum_weightssquared = sum(data[\"SE\"]**2)\n",
      "\n",
      "    # Generates the formula equation\n",
      "    formula = varlist[0] + \" ~ \" + \" + \".join(varlist[1:])\n",
      "\n",
      "    ols_results = smf.ols( formula = formula, data = data).fit()\n",
      "\n",
      "    sum_residsquared = sum(ols_results.resid**2)\n",
      "\n",
      "    sigmasquared = (sum_residsquared - sum_weightssquared + matrix_trace) / (X_T.shape[1] - X_T.shape[0])\n",
      "\n",
      "    weight_FGLS = 1 / np.sqrt(sigmasquared + data[SE]**2)\n",
      "\n",
      "    return weight_FGLS\n",
      "    "
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function to nicely display regression tables by adding stars like estout.\n",
      "# Required args are\n",
      "# dataframe: Dataframe of your data\n",
      "# pvalue_coeff_dict: A dictionary of key : value pairs: pvalue col name : corresponding col name\n",
      "\n",
      "def add_pvaluestars(dataframe, pvalue_coeff_dict):\n",
      "    dataframe = np.round(dataframe, decimals = 5)\n",
      "    for i,r in dataframe.iterrows():\n",
      "        for k in pvalue_coeff_dict.keys():\n",
      "            if r[k] < .01:\n",
      "                r[pvalue_coeff_dict[k]] = str(r[pvalue_coeff_dict[k]]) + \"***\"\n",
      "            elif r[k] < .05 and r[k] >= .01:\n",
      "                r[pvalue_coeff_dict[k]] = str(r[pvalue_coeff_dict[k]]) + \"**\"\n",
      "            elif r[k] < .1 and r[k] >= .05:\n",
      "                r[pvalue_coeff_dict[k]] = str(r[pvalue_coeff_dict[k]]) + \"*\"\n",
      "        \n",
      "        dataframe.loc[i] = r\n",
      "    return dataframe"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "            #### Jenkins's method regression function.\n",
      "            # Uses the ResultsStore class defined above to store results, but can also import it from statsmodels\n",
      "            def jenkins_reg(dataframe, varlist, formula, LS = \"OLS\", weights = None):\n",
      "                # dataframe is a pd.DataFrame with all your observations\n",
      "                # varlist is a list of strings where the first string is the dependent variable and the second onwards are the independent variables\n",
      "                # formula is a string with your desired regression formula\n",
      "                # LS is a string that is either OLS or WLS, depending on the type of regression you want to do\n",
      "                # weights is optional and only required for WLS.\n",
      "\n",
      "                print \"Please ensure that you have scaled your dataframes properly for your chosen method\"\n",
      "\n",
      "                results = ResultsStore()\n",
      "                # Generating regression vars\n",
      "\n",
      "                dictionary = {}\n",
      "                for v in varlist:\n",
      "                    dictionary[v] = dataframe[v]\n",
      "                    data = DataFrame(dictionary)\n",
      "\n",
      "                    # Running Jenkins method regression\n",
      "\n",
      "                    if LS == \"OLS\":\n",
      "                        results.reg = smf.ols(formula = formula , data = data).fit()\n",
      "\n",
      "                    elif LS == \"WLS\":\n",
      "                        results.reg = smf.wls(formula = formula, data = data, weights = weights).fit()\n",
      "\n",
      "                        return results"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        # This is a list of acceptable countries for our analysis because we really don't want to include every minor country as that will\n",
      "        # definitely ruin everything~~~~\n",
      "\n",
      "        # European countries. Must be within mainland Europe.\n",
      "        countries_european = [\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
      "                              \"Denmark\", \"Finland\", \"France\", \"Greece\", \"Hungary\", \"Iceland\", \"Italy\", \"Latvia\", \"Luxembourg\",\n",
      "                              \"Malta\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\",\n",
      "                              \"Spain\", \"Sweden\", \"Switzerland\", \"Ukraine\", \"United Kingdom\"]\n",
      "\n",
      "        # Major countries. Excludes small islands, small nations, and most of the countries with serious turmoil.\n",
      "        countries_major = [\"Algeria\", \"Australia\", \"Austria\", \"Belgium\", \"Brazil\", \"Bulgaria\", \"Canada\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
      "                           \"Denmark\", \"Finland\", \"France\", \"Greece\", \"Hungary\", \"Iceland\", \"Israel\", \"Italy\", \"Latvia\", \"Luxembourg\",\n",
      "                           \"Malta\", \"Mexico\", \"Morocco\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\",\n",
      "                           \"Saudi Arabia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Tunisia\", \"Ukraine\", \"United Kingdom\", \"United States\"]\n",
      "\n",
      "        # Countries that we used in the Stata code\n",
      "        countries_stata = [\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", 'Czech Republic', 'Denmark', 'Finland', 'France',\n",
      "                           'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Latvia', 'Luxembourg', 'Malta', 'Netherlands',\n",
      "                           'Norway', 'Poland', 'Portugal', 'Romania', 'Spain', 'Sweden', 'Switzerland', 'United Kingdom']\n",
      "\n",
      "        # Countries that are in Euro-West Asia-North Africa area\n",
      "        countries_germanycen = [\"Algeria\", \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
      "                                \"Denmark\", \"Finland\", \"France\", \"Greece\", \"Hungary\", \"Iceland\", \"Israel\", \"Italy\", \"Latvia\", \"Luxembourg\",\n",
      "                                \"Malta\", \"Morocco\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\",\n",
      "                                \"Saudi Arabia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Tunisia\", \"Ukraine\", \"United Kingdom\"]\n",
      "\n",
      "        countries_eurocen = [\"Algeria\", \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
      "                             \"Denmark\", \"Finland\", \"France\", \"Greece\", \"Hungary\", \"Iceland\", \"Italy\", \"Latvia\", \"Luxembourg\",\n",
      "                             \"Malta\", \"Morocco\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\",\n",
      "                             \"Spain\", \"Sweden\", \"Switzerland\", \"Tunisia\", \"Ukraine\", \"United Kingdom\"]"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "            # Reading RER data (Change directory path for your needs)\n",
      "            data_raw = pd.read_excel(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\Exchange Rate Data\\Data.xlsx\", sheet=\"DATA\",header=0)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "            # Converting value column to floats\n",
      "            data_raw[\"Value\"] = data_raw[\"Value\"].astype(float)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Importing data for Real Exchange Rates by CPI\n",
      "RER_CPI_raw = data_raw[data_raw[\"Concept Code\"] == \"EREER\"]\n",
      "\n",
      "# Extracting only relevant columns\n",
      "l_col = [\"Country Label\", \"Country Code\", \"Time Code\", \"Value\"]\n",
      "\n",
      "RER_CPI = pd.DataFrame()\n",
      "for a in l_col:\n",
      "    RER_CPI[a] = RER_CPI_raw[a]\n",
      "\n",
      "# Converting time to date time\n",
      "RER_CPI[\"Time Code\"] = pd.to_datetime(data_raw[\"Time Code\"],format=\"%YM%m\")\n",
      "\n",
      "# Converting value to log value\n",
      "RER_CPI[\"Log Value\"] = np.log(RER_CPI[\"Value\"])\n",
      "\n",
      "# Only using European-ish countries. Dropping everything else\n",
      "RER_CPI = RER_CPI.loc[RER_CPI[\"Country Label\"].isin(countries_european)]"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    # Importing distance data\n",
      "    distance = pd.read_excel(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\Country Distances (Deniz Ozensoy's conflicted copy 2015-03-04).xls\")"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    # Importing Balance of Trade data and cleaning it\n",
      "    bal_trade = pd.read_csv(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\hpfilters.csv\")\n",
      "    bal_trade = bal_trade.T\n",
      "    bal_trade.columns = bal_trade.loc[\"Time\"]\n",
      "    bal_trade = bal_trade[1:]\n",
      "\n",
      "    # Arbitrarily removes any rows that have more than 50 nans.\n",
      "    for c in bal_trade.index:\n",
      "        if sum(pd.isnull(bal_trade.loc[c])) > 100:\n",
      "            bal_trade = bal_trade.drop(c)\n",
      "\n",
      "        # Gets average of remaining countries and stores them\n",
      "        bal_trade_means = DataFrame({\"Mean\" : bal_trade.mean(1) })\n",
      "\n",
      "    #bal_trade_means = bal_trade_means.drop([\"Malta\", \"Iceland\", \"Latvia\", \"Iceland\", \"Cyprus\", \"Czech Republic\", \"Slovak Republic\", \"Croatia\", \"Bulgaria\", \"Luxembourg\", \"Romania\", \"Hungary\"],axis=0)\n",
      "    print bal_trade_means\n",
      "    print bal_trade.T.astype(float).describe()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                    Mean\n",
        "Greece          0.050433\n",
        "Netherlands     0.224211\n",
        "United Kingdom  0.055165\n",
        "Malta           0.169262\n",
        "France          0.075427\n",
        "Ireland         0.104634\n",
        "Portugal        0.077941\n",
        "Iceland         0.065481\n",
        "Sweden          0.083511\n",
        "Denmark         0.107983\n",
        "Italy           0.063518\n",
        "Spain           0.050126\n",
        "Norway          0.086008\n",
        "Cyprus          0.061983\n",
        "Austria         0.246800\n",
        "Finland         0.075344\n",
        "           Greece  Netherlands  United Kingdom       Malta      France  \\\n",
        "count  418.000000   420.000000      420.000000  420.000000  419.000000   \n",
        "mean     0.050433     0.224211        0.055165    0.169262    0.075427   \n",
        "std      0.013383     0.038248        0.003359    0.042167    0.005355   \n",
        "min      0.029639     0.171831        0.048529    0.125976    0.066352   \n",
        "25%      0.040083     0.188694        0.053512    0.131423    0.070222   \n",
        "50%      0.046272     0.220484        0.055088    0.147702    0.076902   \n",
        "75%      0.062060     0.247517        0.056735    0.211540    0.079847   \n",
        "max      0.074012     0.292177        0.062381    0.248935    0.087034   \n",
        "\n",
        "          Ireland    Portugal     Iceland      Sweden     Denmark       Italy  \\\n",
        "count  420.000000  420.000000  420.000000  420.000000  420.000000  418.000000   \n",
        "mean     0.104634    0.077941    0.065481    0.083511    0.107983    0.063518   \n",
        "std      0.030756    0.012915    0.008274    0.007777    0.008992    0.003048   \n",
        "min      0.067734    0.052731    0.045793    0.069530    0.090233    0.057630   \n",
        "25%      0.076519    0.066801    0.058492    0.078230    0.099257    0.061127   \n",
        "50%      0.103822    0.081762    0.065332    0.083611    0.111052    0.063299   \n",
        "75%      0.115581    0.089366    0.069036    0.089975    0.115131    0.066292   \n",
        "max      0.174990    0.096064    0.082847    0.095922    0.121317    0.070883   \n",
        "\n",
        "            Spain      Norway      Cyprus     Austria     Finland  \n",
        "count  418.000000  420.000000  418.000000  420.000000  420.000000  \n",
        "mean     0.050126    0.086008    0.061983    0.246800    0.075344  \n",
        "std      0.011552    0.011797    0.010440    0.041093    0.012270  \n",
        "min      0.022162    0.059968    0.044502    0.186354    0.060939  \n",
        "25%      0.047757    0.077631    0.053144    0.206883    0.065048  \n",
        "50%      0.050408    0.083836    0.059205    0.244175    0.071223  \n",
        "75%      0.057883    0.094645    0.069816    0.295697    0.084491  \n",
        "max      0.068077    0.120192    0.085024    0.316429    0.100421  \n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "            # Runs ADF for all countries and returns results in dictionary.\n",
      "            # Results have format: { \"Country\" : [ OLS Coefficient, OLS Standard Error, # of lags ]}\n",
      "\n",
      "# Max lag = 2 chosen in the dataset to make it more comparable for our other results and because that's what we would want to estimate\n",
      "# in our model. An additional thing to try would be to use the autolag = \"t-stat\" command which searches for the first instance\n",
      "# of the lag where the tstat is significant. Unfortunately it breaks currently cuz the code is failing, but I can manually code it.\n",
      "# I know some paper uses it for max lag = 6. Don't remember which.\n",
      "results = {}\n",
      "t = []\n",
      "for a in RER_CPI[\"Country Label\"].unique():\n",
      "    l = []\n",
      "    ad = adfuller_edit(RER_CPI[RER_CPI[\"Country Label\"] == a][\"Log Value\"], regression = 'ct', autolag = 'AIC', regresults = True)\n",
      "    l.append(ad[3].ols.params[0])\n",
      "    l.append(ad[3].ols.bse[0])\n",
      "    l.append(ad[3].usedlag)\n",
      "    t.append(ad[3].ols)\n",
      "    results[a] = l"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### For outputting the ADF results. #####\n",
      "\n",
      "# Results have format: { \"Country\" : [ OLS Coefficient, OLS Standard Error, # of lags, ADF Test Statistic, MacKinnon's approximate p-value,\n",
      "# Observations count, 95% CI Lower, 95% CI Upper]}\n",
      "\n",
      "results_output = {}\n",
      "for a in RER_CPI[\"Country Label\"].unique():\n",
      "    l = []\n",
      "    ad = adfuller_edit(RER_CPI[RER_CPI[\"Country Label\"] == a][\"Log Value\"], regression = 'ct', autolag = 'AIC', regresults = True)\n",
      "    l.append(ad[3].ols.params[0])\n",
      "    l.append(ad[3].ols.bse[0])\n",
      "    l.append(ad[0])\n",
      "    l.append(ad[1])\n",
      "    l.append(ad[3].nobs)\n",
      "    l.append(ad[3].ols.pvalues[0])\n",
      "    results_output[a] = l\n",
      "\n",
      "ADF_results = DataFrame(results_output)\n",
      "ADF_results = ADF_results.T\n",
      "ADF_results.columns = [\"Coefficient\", \"SE\", \"ADF Statistic\", \"ADF p-value\", \"Observations\", \"P Value\"]\n",
      "ADF_results[\"rho\"] = 1 + ADF_results[\"Coefficient\"]"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Formatting results and outputting\n",
      "col = [ 'ADF Statistic', 'ADF p-value', 'rho', 'SE', 'P Value', 'Observations']\n",
      "ADF_results_output = ADF_results.ix[:, col]\n",
      "\n",
      "# Section below will be modified into a p-value function\n",
      "ADF_results_output = add_pvaluestars(ADF_results_output, {\"ADF p-value\" : \"rho\"})\n",
      "\n",
      "ADF_results_output = ADF_results_output.drop([\"P Value\"], axis = 1)\n",
      "\n",
      "#ADF_results_output.to_csv(\"ADF_results.csv\")"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outliers = {}\n",
      "j = 0\n",
      "for i,r in ADF_results.iterrows():\n",
      "    if r[\"rho\"] < .91:\n",
      "        l = []\n",
      "        print j\n",
      "        print i,\n",
      "        print r[\"rho\"]\n",
      "        l.append(i)\n",
      "        l.append(r[\"rho\"])\n",
      "        outliers[j] = l\n",
      "    j = j + 1"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "Bulgaria 0.89277542216\n",
        "3\n",
        "Croatia 0.899399941436\n",
        "20\n",
        "Romania 0.900163051591\n",
        "25\n",
        "Ukraine 0.857086602592\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "### For plotting above ADF results. ###\n",
      "rhoplot = plt.plot(ADF_results[\"rho\"], 'x')\n",
      "plt.xlabel(\"Index\")\n",
      "plt.ylabel(\"rho\")\n",
      "plt.title(\"Estimated rho coefficients\")\n",
      "\n",
      "for k in outliers.keys():\n",
      "    if k == 2:\n",
      "        plt.annotate(outliers[k][0],\n",
      "                     xy = (k,outliers[k][1]), xytext = (40,-90),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                     arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "    elif k == 11:\n",
      "        plt.annotate(outliers[k][0],\n",
      "                     xy = (k,outliers[k][1]), xytext = (-50,-90),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                     arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "    elif k == 20:\n",
      "        plt.annotate(outliers[k][0],\n",
      "                     xy = (k,outliers[k][1]), xytext = (70,-90),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                     arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "    else:\n",
      "        plt.annotate(outliers[k][0],\n",
      "                     xy = (k,outliers[k][1]), xytext = (90,20),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                     arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "        \n",
      "plt.show()"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        test = adfuller_edit(coun[\"Country Label\"] == \"Italy\"][\"Log Value\"], regression = 'ct', autolag = 'AIC', regresults = True)\n",
      "        print test[3].ols.summary()"
     ],
     "language": "python",
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-28-021cd8cddd5c>, line 1)",
       "output_type": "error",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-021cd8cddd5c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    test = adfuller_edit(coun[\"Country Label\"] == \"Italy\"][\"Log Value\"], regression = 'ct', autolag = 'AIC', regresults = True)\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      },
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-28-021cd8cddd5c>, line 1)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-021cd8cddd5c>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    test = adfuller_edit(coun[\"Country Label\"] == \"Italy\"][\"Log Value\"], regression = 'ct', autolag = 'AIC', regresults = True)\u001b[0m\n\u001b[1;37m                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Seeing if we can get the unit root to work for period before and after Schengen period. Leaving this. I'm not sure how to interpret this...\n",
      "\n",
      "uniondates = pd.read_csv(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\Exchange Rate Data\\Country union dates (1).csv\")\n",
      "\n",
      "results_output = {}\n",
      "coun = [\"Belgium\", \"Denmark\", \"France\", \"Greece\", \"Italy\", \"Luxembourg\", \"Netherlands\", \"Portugal\", \"Spain\", \"United Kingdom\"]\n",
      "for a in coun:\n",
      "    coun_test = RER_CPI[RER_CPI[\"Time Code\"] < pd.Timestamp('19920207')]\n",
      "    l = []\n",
      "    ad = adfuller_edit(coun_test[coun_test[\"Country Label\"] == a][\"Log Value\"], regression = 'ct', autolag = 'AIC', regresults = True)\n",
      "    l.append(ad[3].ols.params[0])\n",
      "    l.append(ad[3].ols.bse[0])\n",
      "    l.append(ad[0])\n",
      "    l.append(ad[1])\n",
      "    l.append(ad[3].nobs)\n",
      "    l.append(ad[3].ols.pvalues[0])\n",
      "    results_output[a] = l\n",
      "\n",
      "ADF_results_test = DataFrame(results_output)\n",
      "ADF_results_test = ADF_results_test.T\n",
      "ADF_results_test.columns = [\"Coefficient\", \"SE\", \"ADF Statistic\", \"ADF p-value\", \"Observations\", \"P Value\"]\n",
      "ADF_results_test[\"rho\"] = 1 + ADF_results[\"Coefficient\"]\n",
      "\n",
      "print ADF_results_test\n",
      "# First testing for entry into the EU\n",
      "#eu_countries = uniondates.dropna(axis = 0, how = 'any', subset = [\"Date Entered European Union\"])\n",
      "#eu_countries[\"Date Entered European Union\"] = pd.to_datetime(eu_countries[\"Date Entered European Union\"], format=\"%A, %B %d, %Y\")\n",
      "\n",
      "\n",
      "#eu_countries[eu_countries[\"County\"] == \"France\"][\"Date Entered European Union\"].iloc[0]\n",
      "\n",
      "# RER_CPI[RER_CPI[\"Time Code\"] < eu_countries[eu_countries[\"County\"] == \"France\"][\"Date Entered European Union\"].iloc[0]]\n",
      "\n",
      "# Now testing for entry into the Schengen Zone\n"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                Coefficient        SE  ADF Statistic  ADF p-value  \\\n",
        "Belgium           -0.022829  0.010758      -2.121977     0.533770   \n",
        "Denmark           -0.041310  0.014779      -2.795197     0.198714   \n",
        "France            -0.046481  0.019451      -2.389719     0.385099   \n",
        "Greece            -0.053956  0.031142      -1.732592     0.736319   \n",
        "Italy             -0.100255  0.029289      -3.422984     0.048392   \n",
        "Luxembourg        -0.053297  0.027242      -1.956453     0.624940   \n",
        "Netherlands       -0.046792  0.016835      -2.779368     0.204625   \n",
        "Portugal          -0.015604  0.020830      -0.749122     0.969712   \n",
        "Spain             -0.030103  0.012241      -2.459101     0.348702   \n",
        "United Kingdom    -0.072323  0.020597      -3.511354     0.038192   \n",
        "\n",
        "                Observations   P Value       rho  \n",
        "Belgium                  154  0.035505  0.974431  \n",
        "Denmark                  156  0.005856  0.958670  \n",
        "France                   145  0.018183  0.968354  \n",
        "Greece                   143  0.085402  0.967384  \n",
        "Italy                    140  0.000825  0.982441  \n",
        "Luxembourg               154  0.052294  0.976984  \n",
        "Netherlands              156  0.006135  0.968061  \n",
        "Portugal                 153  0.454989  0.984969  \n",
        "Spain                    144  0.015148  0.984500  \n",
        "United Kingdom           156  0.000587  0.961069  \n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# l contains a list of countries that are exact matches between our distance and RER data\n",
      "l = []\n",
      "for i in results.keys():\n",
      "    for j in distance[\"Name\"]:\n",
      "        if i == j:\n",
      "            l.append(i)\n",
      "\n",
      "            # prints a list of countries that are in RER data but not in distance. Highly likely most are due to names not being exact matches\n",
      "            for i in results.keys():\n",
      "                if i not in l:\n",
      "                    pass\n",
      "                #print i"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates new data frame with the results from the ADF dictionary above\n",
      "jenkins = DataFrame(results)\n",
      "jenkins = jenkins.T\n",
      "jenkins.columns = [\"Coefficient\", \"SE\", \"Used Lags\"]\n",
      "\n",
      "# Merges data with distance based on intersection of country names and generates log distance\n",
      "jenkins = pd.merge(jenkins, distance, left_index = True, right_on = \"Name\")\n",
      "jenkins[\"log_dist\"] = np.log(jenkins[\"dist\"])\n",
      "\n",
      "# Generates the rho coefficients\n",
      "jenkins[\"rho\"] = 1 + jenkins[\"Coefficient\"]\n",
      "jenkins.columns\n",
      "\n",
      "# Deleting useless columns\n",
      "jenkins = jenkins.drop(['From', 'To', 'colony', 'comcol', 'curcol', 'col45', 'smctry'], axis=1)"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Uses all countries in our data set\n",
      "weights = 1/(jenkins[\"SE\"]**2)\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist', data = jenkins, weights = weights).fit()\n",
      "print wls_results.summary()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.042\n",
        "Model:                            WLS   Adj. R-squared:                  0.004\n",
        "Method:                 Least Squares   F-statistic:                     1.109\n",
        "Date:                Fri, 13 Mar 2015   Prob (F-statistic):              0.302\n",
        "Time:                        16:35:06   Log-Likelihood:                 68.405\n",
        "No. Observations:                  27   AIC:                            -132.8\n",
        "Df Residuals:                      25   BIC:                            -130.2\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.9448      0.028     33.790      0.000         0.887     1.002\n",
        "log_dist       0.0043      0.004      1.053      0.302        -0.004     0.013\n",
        "==============================================================================\n",
        "Omnibus:                        1.465   Durbin-Watson:                   1.410\n",
        "Prob(Omnibus):                  0.481   Jarque-Bera (JB):                0.653\n",
        "Skew:                          -0.365   Prob(JB):                        0.722\n",
        "Kurtosis:                       3.220   Cond. No.                         59.4\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Examines a subset of the data where countries are on the same continent as Germany\n",
      "jenkins_germanycen = jenkins.loc[jenkins[\"Name\"].isin(countries_germanycen)]\n",
      "\n",
      "weights = 1/(jenkins_germanycen[\"SE\"]**2)\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist', data = jenkins_germanycen, weights = weights).fit()\n",
      "print wls_results.summary()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.042\n",
        "Model:                            WLS   Adj. R-squared:                  0.004\n",
        "Method:                 Least Squares   F-statistic:                     1.109\n",
        "Date:                Fri, 13 Mar 2015   Prob (F-statistic):              0.302\n",
        "Time:                        16:35:07   Log-Likelihood:                 68.405\n",
        "No. Observations:                  27   AIC:                            -132.8\n",
        "Df Residuals:                      25   BIC:                            -130.2\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.9448      0.028     33.790      0.000         0.887     1.002\n",
        "log_dist       0.0043      0.004      1.053      0.302        -0.004     0.013\n",
        "==============================================================================\n",
        "Omnibus:                        1.465   Durbin-Watson:                   1.410\n",
        "Prob(Omnibus):                  0.481   Jarque-Bera (JB):                0.653\n",
        "Skew:                          -0.365   Prob(JB):                        0.722\n",
        "Kurtosis:                       3.220   Cond. No.                         59.4\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Examines just the distance model\n",
      "jenkins_european = jenkins.loc[jenkins[\"Name\"].isin(countries_european)]\n",
      "\n",
      "weights = 1/(jenkins_european[\"SE\"]**2)\n",
      "\n",
      "# Running Jenkins method regression\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist', data = jenkins_european, weights = weights).fit()\n",
      "print wls_results.summary()\n",
      "\n",
      "ols_results = smf.ols(formula = 'rho ~ log_dist', data = jenkins_european).fit()\n",
      "print ols_results.HC1_se"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.042\n",
        "Model:                            WLS   Adj. R-squared:                  0.004\n",
        "Method:                 Least Squares   F-statistic:                     1.109\n",
        "Date:                Fri, 13 Mar 2015   Prob (F-statistic):              0.302\n",
        "Time:                        16:35:08   Log-Likelihood:                 68.405\n",
        "No. Observations:                  27   AIC:                            -132.8\n",
        "Df Residuals:                      25   BIC:                            -130.2\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.9448      0.028     33.790      0.000         0.887     1.002\n",
        "log_dist       0.0043      0.004      1.053      0.302        -0.004     0.013\n",
        "==============================================================================\n",
        "Omnibus:                        1.465   Durbin-Watson:                   1.410\n",
        "Prob(Omnibus):                  0.481   Jarque-Bera (JB):                0.653\n",
        "Skew:                          -0.365   Prob(JB):                        0.722\n",
        "Kurtosis:                       3.220   Cond. No.                         59.4\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "Intercept    0.036672\n",
        "log_dist     0.006103\n",
        "dtype: float64"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = LewisLinzerWeights(jenkins_european, [\"rho\", \"log_dist\"], \"SE\")\n",
      "\n",
      "wls_results = smf.wls(formula = \"rho ~ log_dist\", data = jenkins_european, weights = weights).fit()\n",
      "print wls_results.summary()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.011\n",
        "Model:                            WLS   Adj. R-squared:                 -0.029\n",
        "Method:                 Least Squares   F-statistic:                    0.2707\n",
        "Date:                Fri, 13 Mar 2015   Prob (F-statistic):              0.607\n",
        "Time:                        16:35:09   Log-Likelihood:                 57.233\n",
        "No. Observations:                  27   AIC:                            -110.5\n",
        "Df Residuals:                      25   BIC:                            -107.9\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.9891      0.053     18.639      0.000         0.880     1.098\n",
        "log_dist      -0.0040      0.008     -0.520      0.607        -0.020     0.012\n",
        "==============================================================================\n",
        "Omnibus:                       12.331   Durbin-Watson:                   1.740\n",
        "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               11.228\n",
        "Skew:                          -1.450   Prob(JB):                      0.00365\n",
        "Kurtosis:                       4.255   Cond. No.                         64.3\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Integrating the balance of trade data into Jenkins regression\n",
      "jenkins_baltrade = pd.merge(jenkins, bal_trade_means, left_on = \"Name\", right_index = True)\n",
      "\n",
      "#hpfilters = pd.read_csv(\"C:\\HOME\\IPython\\hpfilters.csv\")\n",
      "#hpfilters = hpfilters.T\n",
      "#print sorted(hpfilters.dropna(how='all').index.tolist())\n",
      "#print \"NOT NULL\"\n",
      "#print jenkins_baltrade[\"Name\"].unique()\n",
      "# Generating regression vars\n",
      "\n",
      "weights = 1/(jenkins_baltrade[\"SE\"]**2)\n",
      "\n",
      "# Running Jenkins method regression\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist + Mean', data = jenkins_baltrade, weights = weights).fit()\n",
      "print wls_results.summary()"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.517\n",
        "Model:                            WLS   Adj. R-squared:                  0.436\n",
        "Method:                 Least Squares   F-statistic:                     6.417\n",
        "Date:                Fri, 13 Mar 2015   Prob (F-statistic):             0.0127\n",
        "Time:                        16:35:09   Log-Likelihood:                 50.553\n",
        "No. Observations:                  15   AIC:                            -95.11\n",
        "Df Residuals:                      12   BIC:                            -92.98\n",
        "Df Model:                           2                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.8838      0.027     33.197      0.000         0.826     0.942\n",
        "log_dist       0.0119      0.004      3.398      0.005         0.004     0.020\n",
        "Mean           0.0912      0.038      2.390      0.034         0.008     0.174\n",
        "==============================================================================\n",
        "Omnibus:                        1.496   Durbin-Watson:                   1.871\n",
        "Prob(Omnibus):                  0.473   Jarque-Bera (JB):                0.941\n",
        "Skew:                           0.266   Prob(JB):                        0.625\n",
        "Kurtosis:                       1.895   Cond. No.                         131.\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\scipy\\stats\\stats.py:1205: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=15\n",
        "  int(n))\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = LewisLinzerWeights(jenkins_baltrade, [\"rho\", \"log_dist\", \"Mean\"], \"SE\")\n",
      "\n",
      "wls_results2 = smf.wls(formula = 'rho ~ log_dist + Mean', data = jenkins_baltrade, weights = weights).fit()\n",
      "wls_results2.summary()\n",
      "\n",
      "#print summary_col([wls_results,wls_results2], stars = True, float_format = '%0.5f').as_latex()"
     ],
     "language": "python",
     "outputs": [
      {
       "html": [
        "<table class=\"simpletable\">\n",
        "<caption>WLS Regression Results</caption>\n",
        "<tr>\n",
        "  <th>Dep. Variable:</th>           <td>rho</td>       <th>  R-squared:         </th> <td>   0.451</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.359</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.922</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Date:</th>             <td>Fri, 13 Mar 2015</td> <th>  Prob (F-statistic):</th>  <td>0.0275</td> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Time:</th>                 <td>16:35:11</td>     <th>  Log-Likelihood:    </th> <td>  50.269</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>No. Observations:</th>      <td>    15</td>      <th>  AIC:               </th> <td>  -94.54</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Residuals:</th>          <td>    12</td>      <th>  BIC:               </th> <td>  -92.41</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Intercept</th> <td>    0.8876</td> <td>    0.028</td> <td>   31.217</td> <td> 0.000</td> <td>    0.826     0.950</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>log_dist</th>  <td>    0.0111</td> <td>    0.004</td> <td>    2.979</td> <td> 0.012</td> <td>    0.003     0.019</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Mean</th>      <td>    0.0928</td> <td>    0.042</td> <td>    2.192</td> <td> 0.049</td> <td>    0.001     0.185</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table class=\"simpletable\">\n",
        "<tr>\n",
        "  <th>Omnibus:</th>       <td> 0.671</td> <th>  Durbin-Watson:     </th> <td>   2.009</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Prob(Omnibus):</th> <td> 0.715</td> <th>  Jarque-Bera (JB):  </th> <td>   0.606</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Skew:</th>          <td> 0.055</td> <th>  Prob(JB):          </th> <td>   0.738</td>\n",
        "</tr>\n",
        "<tr>\n",
        "  <th>Kurtosis:</th>      <td> 2.021</td> <th>  Cond. No.          </th> <td>    136.</td>\n",
        "</tr>\n",
        "</table>"
       ],
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "<class 'statsmodels.iolib.summary.Summary'>\n",
        "\"\"\"\n",
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.451\n",
        "Model:                            WLS   Adj. R-squared:                  0.359\n",
        "Method:                 Least Squares   F-statistic:                     4.922\n",
        "Date:                Fri, 13 Mar 2015   Prob (F-statistic):             0.0275\n",
        "Time:                        16:35:11   Log-Likelihood:                 50.269\n",
        "No. Observations:                  15   AIC:                            -94.54\n",
        "Df Residuals:                      12   BIC:                            -92.41\n",
        "Df Model:                           2                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.8876      0.028     31.217      0.000         0.826     0.950\n",
        "log_dist       0.0111      0.004      2.979      0.012         0.003     0.019\n",
        "Mean           0.0928      0.042      2.192      0.049         0.001     0.185\n",
        "==============================================================================\n",
        "Omnibus:                        0.671   Durbin-Watson:                   2.009\n",
        "Prob(Omnibus):                  0.715   Jarque-Bera (JB):                0.606\n",
        "Skew:                           0.055   Prob(JB):                        0.738\n",
        "Kurtosis:                       2.021   Cond. No.                         136.\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "\"\"\""
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Generating and plotting the effect of distance and bilateral trade on rho\n",
      "\n",
      "wls_dist_coeff = wls_results.params[1]\n",
      "wls_trade_coeff = wls_results.params[2]\n",
      "\n",
      "fgls_dist_coeff = wls_results2.params[1]\n",
      "fgls_trade_coeff = wls_results2.params[2]\n",
      "\n",
      "# Getting countries and their distance\n",
      "dist = DataFrame({ \"Name\" : jenkins_baltrade[\"Name\"], \"log_dist\" : jenkins_baltrade[\"log_dist\"]})\n",
      "\n",
      "# Getting countries and their bilateral trade\n",
      "trade = DataFrame({ \"Name\" : jenkins_baltrade[\"Name\"], \"Mean\" : jenkins_baltrade[\"Mean\"]})\n",
      "\n",
      "dist[\"Estimated Effect (WLS)\"] = dist[\"log_dist\"]*wls_dist_coeff\n",
      "dist[\"Estimated Effect (FGLS)\"] = dist[\"log_dist\"]*fgls_dist_coeff\n",
      "\n",
      "dist = dist.sort(\"log_dist\")\n",
      "dist.to_csv(\"Estimated Distance.csv\")\n",
      "\n",
      "trade[\"Estimated Effect (WLS)\"] = trade[\"Mean\"]*wls_trade_coeff\n",
      "trade[\"Estimated Effect (FGLS)\"] = trade[\"Mean\"]*fgls_trade_coeff\n",
      "\n",
      "trade = trade.sort(\"Mean\")\n",
      "trade.to_csv(\"Estimated Trade.csv\")"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Generating plot of distance versus estimated effect of distance on rho ###\n",
      "def plot_rho_dist(data, x, y, label):\n",
      "    plt.plot(data[x], data[y], 'x', label = label)\n",
      "    plt.xlabel(x)\n",
      "    plt.ylabel(y)\n",
      "\n",
      "    \n",
      "plot_rho_dist(trade, \"Mean\", \"Estimated Effect (WLS)\", \"WLS\")\n",
      "plot_rho_dist(trade, \"Mean\", \"Estimated Effect (FGLS)\", \"FGLS\")\n",
      "plt.legend(bbox_to_anchor=(0.5,1))\n",
      "plt.title(\"Estimated Effect of Trade on rho\")\n",
      "plt.show()"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "    for n in data[\"Name\"]:\n",
      "        if 'd' in n:\n",
      "            plt.annotate(n,\n",
      "                     xy = (data[data[\"Name\"] == n][x], data[data[\"Name\"] == n][y]), xytext = (20,-30),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                         arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "        elif n == 'Greece':\n",
      "            plt.annotate(n,\n",
      "                     xy = (data[data[\"Name\"] == n][x], data[data[\"Name\"] == n][y]), xytext = (40,-30),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                         arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "                \n",
      "        else:\n",
      "            plt.annotate(n,\n",
      "                     xy = (data[data[\"Name\"] == n][x], data[data[\"Name\"] == n][y]), xytext = (20,30),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                         arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'United Kingdom blahb lah' < 'n'"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 211,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 211
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets a list of countries for which we have less than a certain number of data points\n",
      "for a in RER_CPI[\"Country Label\"].unique():\n",
      "    if RER_CPI[RER_CPI[\"Country Label\"] == str(a)][\"Time Code\"].min() > pd.Timestamp('19790101'):\n",
      "        pass\n",
      "#         print a\n",
      "#         print RER_CPI[RER_CPI[\"Country Label\"] == str(a)][\"Time Code\"].min()"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        # Super hackish way to get google docs to format stuff nicely.\n",
      "        str = \"\"\"Country        ADF Statistic   p-value         rho     Std. Err.       t       P>| t |         95% CIL         95% CIU\n",
      "Austria         -3.352  0.0581  0.9749732       0.0074661       -3.35   0.001   0.9602981       0.9896482\n",
      "Belgium         -2.473  0.3417  0.9803126       0.0079615       -2.47   0.014   0.9646638       0.9959615\n",
      "Bulgaria        -4.206  0.0044  0.9030904       0.0230392       -4021   0       0.8577304       0.9484504\n",
      "Croatia         -2.923  0.1549  0.9499666       0.0171169       -2.92   0.004   0.9162647       0.9836685\n",
      "Cyprus  -1.369  0.8699  0.9902017       0.0071586       -1.37   0.172   0.9761297       1.0042736\n",
      "Czech Republic  -2.527  0.3147  0.9466014       0.0211333       -2.53   0.012   0.905009        0.9881938\n",
      "Denmark         -2.394  0.3828  0.976163        0.0099572       -2.39   0.017   0.9565915       0.957344\n",
      "Finland         -2.538  0.3903  0.9775861       0.0092781       -2.21   0.016   0.9593481       0.9958241\n",
      "France  -2.419  0.3713  0.9775861       0.0092781       -2.42   0.016   0.9593481       0.9958241\n",
      "Greece  -2.879  0.1695  0.9642326       0.0124237       -2.88   0.004   0.9398111       0.9886542\n",
      "Hungary         -2.407  0.3757  0.9772322       0.0094575       -2.41   0.017   0.9586414       0.995823\n",
      "Iceland         -3.284  0.069   0.9649166       0.0106846       -3.28   0.001   0.9439153       0.9859179\n",
      "Ireland         -2.829  0.1863  0.9838948       0.005692        -2.83   0.005   0.9727068       0.9950829\n",
      "Italy   -2.41   0.3745  0.9831155       0.0070068       -2.41   0.016   0.9693421       0.9968889\n",
      "Lativa  -3.566  0.0328  0.9454487       0.0152976       -3.57   0       0.9153304       0.975567\n",
      "Luxemburg       -2.443  0.357   0.9782142       0.0089178       -2.44   0.015   0.9606857       0.9957428\n",
      "Malta   -1.065  0.9347  0.994958        0.0047349       -1.06   0.288   0.9856513       1.0042647\n",
      "Norway  -1.451  0.8454  0.9928809       0.004907        -1.45   0.148   0.9832358       1.002526\n",
      "Netherlands     -2.612  0.2746  0.9772406       0.0087149       -2.61   0.009   0.9601109       0.9943703\n",
      "Poland  -3.94   0.0107  0.9446897       0.0140371       -3.94   0.001   0.9170721       0.9723073\n",
      "Portugal        -3.522  0.0371  0.9619046       0.0108179       -3.52   0       0.9406414       0.9831678\n",
      "Romania         -4.332  0.0028  0.8684964       0.030542        -4.33   0       0.8087485       0.9282442\n",
      "Slovak Republic         -3.189  0.0867  0.958842        0.012907        -3.19   0.002   0.9334397       0.9842442\n",
      "Spain   -1.98   0.6121  0.985733        0.0072043       -1.98   0.048   0.9715714       0.9998946\n",
      "Sweden  -3.292  0.0371  0.965096        0.010602        -3.29   0.001   0.9442572       0.9859349\n",
      "Switzerland     -2.495  0.0028  0.8684964       0.030542        -4.33   0.013   0.8087485       0.9282442\n",
      "United Kingdom  -3.696  0.0226  0.9665722       0.0090443       -3.7    0       0.9487951       0.9843493\n",
      "\n",
      "\"\"\"\n",
      "print str.expandtabs(15)\n",
      "# with open('ADF2.txt', 'wb') as file:\n",
      "#     file.write(str.expandtabs(25))"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Country        ADF Statistic  p-value        rho            Std. Err.      t              P>| t |        95% CIL        95% CIU\n",
        "Austria        -3.352         0.0581         0.9749732      0.0074661      -3.35          0.001          0.9602981      0.9896482\n",
        "Belgium        -2.473         0.3417         0.9803126      0.0079615      -2.47          0.014          0.9646638      0.9959615\n",
        "Bulgaria       -4.206         0.0044         0.9030904      0.0230392      -4021          0              0.8577304      0.9484504\n",
        "Croatia        -2.923         0.1549         0.9499666      0.0171169      -2.92          0.004          0.9162647      0.9836685\n",
        "Cyprus         -1.369         0.8699         0.9902017      0.0071586      -1.37          0.172          0.9761297      1.0042736\n",
        "Czech Republic -2.527         0.3147         0.9466014      0.0211333      -2.53          0.012          0.905009       0.9881938\n",
        "Denmark        -2.394         0.3828         0.976163       0.0099572      -2.39          0.017          0.9565915      0.957344\n",
        "Finland        -2.538         0.3903         0.9775861      0.0092781      -2.21          0.016          0.9593481      0.9958241\n",
        "France         -2.419         0.3713         0.9775861      0.0092781      -2.42          0.016          0.9593481      0.9958241\n",
        "Greece         -2.879         0.1695         0.9642326      0.0124237      -2.88          0.004          0.9398111      0.9886542\n",
        "Hungary        -2.407         0.3757         0.9772322      0.0094575      -2.41          0.017          0.9586414      0.995823\n",
        "Iceland        -3.284         0.069          0.9649166      0.0106846      -3.28          0.001          0.9439153      0.9859179\n",
        "Ireland        -2.829         0.1863         0.9838948      0.005692       -2.83          0.005          0.9727068      0.9950829\n",
        "Italy          -2.41          0.3745         0.9831155      0.0070068      -2.41          0.016          0.9693421      0.9968889\n",
        "Lativa         -3.566         0.0328         0.9454487      0.0152976      -3.57          0              0.9153304      0.975567\n",
        "Luxemburg      -2.443         0.357          0.9782142      0.0089178      -2.44          0.015          0.9606857      0.9957428\n",
        "Malta          -1.065         0.9347         0.994958       0.0047349      -1.06          0.288          0.9856513      1.0042647\n",
        "Norway         -1.451         0.8454         0.9928809      0.004907       -1.45          0.148          0.9832358      1.002526\n",
        "Netherlands    -2.612         0.2746         0.9772406      0.0087149      -2.61          0.009          0.9601109      0.9943703\n",
        "Poland         -3.94          0.0107         0.9446897      0.0140371      -3.94          0.001          0.9170721      0.9723073\n",
        "Portugal       -3.522         0.0371         0.9619046      0.0108179      -3.52          0              0.9406414      0.9831678\n",
        "Romania        -4.332         0.0028         0.8684964      0.030542       -4.33          0              0.8087485      0.9282442\n",
        "Slovak Republic               -3.189         0.0867         0.958842       0.012907       -3.19          0.002          0.9334397      0.9842442\n",
        "Spain          -1.98          0.6121         0.985733       0.0072043      -1.98          0.048          0.9715714      0.9998946\n",
        "Sweden         -3.292         0.0371         0.965096       0.010602       -3.29          0.001          0.9442572      0.9859349\n",
        "Switzerland    -2.495         0.0028         0.8684964      0.030542       -4.33          0.013          0.8087485      0.9282442\n",
        "United Kingdom -3.696         0.0226         0.9665722      0.0090443      -3.7           0              0.9487951      0.9843493\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Last cell reserved for outputting results to a csv\n",
      "# with open('Results.csv', 'wb') as csvfile:\n",
      "#     writer = csv.writer(csvfile)\n",
      "#     for r in RER_CPI[RER_CPI[\"Country Label\"] == \"France\"][\"Log Value\"]:\n",
      "#         writer.writerow([r])\n",
      "\n",
      "jenkins.to_csv(\"Results_Jenkins.csv\")"
     ],
     "language": "python",
     "outputs": [],
     "prompt_number": 216
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test cell for various things:\n",
      "\n",
      "test = pd.read_csv(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\merged_data.csv\")\n",
      "test[test[\"Counterpart Country Name\"] == \"Switzerland\"][\"Value_x\"]"
     ],
     "language": "python",
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 106,
       "text": [
        "7594    639000000\n",
        "7595    425600000\n",
        "7596    530700000\n",
        "7597    882900000\n",
        "7598    851000000\n",
        "7599    581900000\n",
        "7600    806000000\n",
        "7601    494900000\n",
        "7602    418900000\n",
        "7603    695800000\n",
        "7604    770700000\n",
        "7605    494100000\n",
        "7606    426300000\n",
        "7607    683500000\n",
        "7608    739600000\n",
        "...\n",
        "8439    4335222000\n",
        "8440    5642056400\n",
        "8441    4791952400\n",
        "8442    4453172600\n",
        "8443    5426426300\n",
        "8444    4370371000\n",
        "8445    5241718100\n",
        "8446    4226640100\n",
        "8447    5200210000\n",
        "8448    4844107600\n",
        "8449    5355914800\n",
        "8450    3462819300\n",
        "8451    4716622600\n",
        "8452    4140941500\n",
        "8453    5104623900\n",
        "Name: Value_x, Length: 860, dtype: float64"
       ]
      }
     ],
     "prompt_number": 106
    }
   ]
  }
 ]
}