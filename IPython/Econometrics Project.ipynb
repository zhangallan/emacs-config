{
 "metadata": {
  "name": "",
  "signature": "sha256:3a29ff61b9a29ed47a34e631a722180d732a4fb392d0d47ecb881c475663f50d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import csv\n",
      "import numpy as np\n",
      "from pandas import Series, DataFrame\n",
      "import statsmodels.api as sm\n",
      "import statsmodels.formula.api as smf\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.dates as mdates\n",
      "import os\n",
      "import datetime as dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This and the next cell are only here because I needed to hack the source code of statsmodels to get it to return the regression coefficient\n",
      "from scipy import stats, signal\n",
      "from statsmodels.regression.linear_model import OLS, yule_walker\n",
      "from statsmodels.tools.tools import add_constant\n",
      "from statsmodels.tsa.tsatools import lagmat, lagmat2ds, add_trend\n",
      "from statsmodels.tsa.adfvalues import mackinnonp, mackinnoncrit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# See comment in previous cell\n",
      "class ResultsStore(object):\n",
      "    def __str__(self):\n",
      "        return self._str  # pylint: disable=E1101\n",
      "\n",
      "def _autolag(mod, endog, exog, startlag, maxlag, method, modargs=(),\n",
      "        fitargs=(), regresults=False):\n",
      "    \"\"\"\n",
      "    Returns the results for the lag length that maximimizes the info criterion.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    mod : Model class\n",
      "        Model estimator class.\n",
      "    modargs : tuple\n",
      "        args to pass to model.  See notes.\n",
      "    fitargs : tuple\n",
      "        args to pass to fit.  See notes.\n",
      "    lagstart : int\n",
      "        The first zero-indexed column to hold a lag.  See Notes.\n",
      "    maxlag : int\n",
      "        The highest lag order for lag length selection.\n",
      "    method : str {\"aic\",\"bic\",\"t-stat\"}\n",
      "        aic - Akaike Information Criterion\n",
      "        bic - Bayes Information Criterion\n",
      "        t-stat - Based on last lag\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    icbest : float\n",
      "        Best information criteria.\n",
      "    bestlag : int\n",
      "        The lag length that maximizes the information criterion.\n",
      "\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    Does estimation like mod(endog, exog[:,:i], *modargs).fit(*fitargs)\n",
      "    where i goes from lagstart to lagstart+maxlag+1.  Therefore, lags are\n",
      "    assumed to be in contiguous columns from low to high lag length with\n",
      "    the highest lag in the last column.\n",
      "    \"\"\"\n",
      "    #TODO: can tcol be replaced by maxlag + 2?\n",
      "    #TODO: This could be changed to laggedRHS and exog keyword arguments if\n",
      "    #    this will be more general.\n",
      "\n",
      "    results = {}\n",
      "    method = method.lower()\n",
      "    for lag in range(startlag, startlag+maxlag+1):\n",
      "        mod_instance = mod(endog, exog[:,:lag], *modargs)\n",
      "        results[lag] = mod_instance.fit()\n",
      "\n",
      "    if method == \"aic\":\n",
      "        icbest, bestlag = min((v.aic,k) for k,v in results.iteritems())\n",
      "    elif method == \"bic\":\n",
      "        icbest, bestlag = min((v.bic,k) for k,v in results.iteritems())\n",
      "    elif method == \"t-stat\":\n",
      "        lags = sorted(results.keys())[::-1]\n",
      "        #stop = stats.norm.ppf(.95)\n",
      "        stop = 1.6448536269514722\n",
      "        for lag in range(startlag + maxlag, startlag - 1, -1):\n",
      "            icbest = np.abs(results[lag].tvalues[-1])\n",
      "            if np.abs(icbest) >= stop:\n",
      "                bestlag = lag\n",
      "                icbest = icbest\n",
      "                break\n",
      "    else:\n",
      "        raise ValueError(\"Information Criterion %s not understood.\") % method\n",
      "\n",
      "    if not regresults:\n",
      "        return icbest, bestlag\n",
      "    else:\n",
      "        return icbest, bestlag, results\n",
      "\n",
      "def adfuller_edit(x, maxlag=None, regression=\"c\", autolag='AIC',\n",
      "    store=False, regresults=False):\n",
      "    '''Augmented Dickey-Fuller unit root test\n",
      "\n",
      "    The Augmented Dickey-Fuller test can be used to test for a unit root in a\n",
      "    univariate process in the presence of serial correlation.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    x : array_like, 1d\n",
      "        data series\n",
      "    maxlag : int\n",
      "        Maximum lag which is included in test, default 12*(nobs/100)^{1/4}\n",
      "    regression : str {'c','ct','ctt','nc'}\n",
      "        Constant and trend order to include in regression\n",
      "        * 'c' : constant only\n",
      "        * 'ct' : constant and trend\n",
      "        * 'ctt' : constant, and linear and quadratic trend\n",
      "        * 'nc' : no constant, no trend\n",
      "    autolag : {'AIC', 'BIC', 't-stat', None}\n",
      "        * if None, then maxlag lags are used\n",
      "        * if 'AIC' or 'BIC', then the number of lags is chosen to minimize the\n",
      "          corresponding information criterium\n",
      "        * 't-stat' based choice of maxlag.  Starts with maxlag and drops a\n",
      "          lag until the t-statistic on the last lag length is significant at\n",
      "          the 95 % level.\n",
      "    store : bool\n",
      "        If True, then a result instance is returned additionally to\n",
      "        the adf statistic\n",
      "    regresults : bool\n",
      "        If True, the full regression results are returned.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    adf : float\n",
      "        Test statistic\n",
      "    pvalue : float\n",
      "        MacKinnon's approximate p-value based on MacKinnon (1994)\n",
      "    usedlag : int\n",
      "        Number of lags used.\n",
      "    nobs : int\n",
      "        Number of observations used for the ADF regression and calculation of\n",
      "        the critical values.\n",
      "    critical values : dict\n",
      "        Critical values for the test statistic at the 1 %, 5 %, and 10 % levels.\n",
      "        Based on MacKinnon (2010)\n",
      "    icbest : float\n",
      "        The maximized information criterion if autolag is not None.\n",
      "    regresults : RegressionResults instance\n",
      "        The\n",
      "    resstore : (optional) instance of ResultStore\n",
      "        an instance of a dummy class with results attached as attributes\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The null hypothesis of the Augmented Dickey-Fuller is that there is a unit\n",
      "    root, with the alternative that there is no unit root. If the pvalue is\n",
      "    above a critical size, then we cannot reject that there is a unit root.\n",
      "\n",
      "    The p-values are obtained through regression surface approximation from\n",
      "    MacKinnon 1994, but using the updated 2010 tables.\n",
      "    If the p-value is close to significant, then the critical values should be\n",
      "    used to judge whether to accept or reject the null.\n",
      "\n",
      "    The autolag option and maxlag for it are described in Greene.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    see example script\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    Greene\n",
      "    Hamilton\n",
      "\n",
      "\n",
      "    P-Values (regression surface approximation)\n",
      "    MacKinnon, J.G. 1994.  \"Approximate asymptotic distribution functions for\n",
      "    unit-root and cointegration tests.  `Journal of Business and Economic\n",
      "    Statistics` 12, 167-76.\n",
      "\n",
      "    Critical values\n",
      "    MacKinnon, J.G. 2010. \"Critical Values for Cointegration Tests.\"  Queen's\n",
      "    University, Dept of Economics, Working Papers.  Available at\n",
      "    http://ideas.repec.org/p/qed/wpaper/1227.html\n",
      "\n",
      "    '''\n",
      "\n",
      "    if regresults:\n",
      "        store = True\n",
      "\n",
      "    trenddict = {None:'nc', 0:'c', 1:'ct', 2:'ctt'}\n",
      "    if regression is None or isinstance(regression, int):\n",
      "        regression = trenddict[regression]\n",
      "    regression = regression.lower()\n",
      "    if regression not in ['c','nc','ct','ctt']:\n",
      "        raise ValueError(\"regression option %s not understood\") % regression\n",
      "    x = np.asarray(x)\n",
      "    nobs = x.shape[0]\n",
      "\n",
      "    if maxlag is None:\n",
      "        #from Greene referencing Schwert 1989\n",
      "        maxlag = int(np.ceil(12. * np.power(nobs/100., 1/4.)))\n",
      "\n",
      "    xdiff = np.diff(x)\n",
      "    xdall = lagmat(xdiff[:,None], maxlag, trim='both', original='in')\n",
      "    nobs = xdall.shape[0]  # pylint: disable=E1103\n",
      "\n",
      "    xdall[:,0] = x[-nobs-1:-1] # replace 0 xdiff with level of x\n",
      "    xdshort = xdiff[-nobs:]\n",
      "\n",
      "    if store:\n",
      "        resstore = ResultsStore()\n",
      "    if autolag:\n",
      "        if regression != 'nc':\n",
      "            fullRHS = add_trend(xdall, regression, prepend=True)\n",
      "        else:\n",
      "            fullRHS = xdall\n",
      "        startlag = fullRHS.shape[1] - xdall.shape[1] + 1 # 1 for level  # pylint: disable=E1103\n",
      "        #search for lag length with smallest information criteria\n",
      "        #Note: use the same number of observations to have comparable IC\n",
      "        #aic and bic: smaller is better\n",
      "\n",
      "        if not regresults:\n",
      "            icbest, bestlag = _autolag(OLS, xdshort, fullRHS, startlag,\n",
      "                                       maxlag, autolag)\n",
      "        else:\n",
      "            icbest, bestlag, alres = _autolag(OLS, xdshort, fullRHS, startlag,\n",
      "                                        maxlag, autolag, regresults=regresults)\n",
      "            resstore.autolag_results = alres\n",
      "\n",
      "        bestlag -= startlag  #convert to lag not column index\n",
      "\n",
      "        #rerun ols with best autolag\n",
      "        xdall = lagmat(xdiff[:,None], bestlag, trim='both', original='in')\n",
      "        nobs = xdall.shape[0]   # pylint: disable=E1103\n",
      "        xdall[:,0] = x[-nobs-1:-1] # replace 0 xdiff with level of x\n",
      "        xdshort = xdiff[-nobs:]\n",
      "        usedlag = bestlag\n",
      "    else:\n",
      "        usedlag = maxlag\n",
      "        icbest = None\n",
      "    if regression != 'nc':\n",
      "        resols = OLS(xdshort, add_trend(xdall[:,:usedlag+1], regression)).fit()\n",
      "    else:\n",
      "        resols = OLS(xdshort, xdall[:,:usedlag+1]).fit()\n",
      "\n",
      "    adfstat = resols.tvalues[0]\n",
      "#    adfstat = (resols.params[0]-1.0)/resols.bse[0]\n",
      "    # the \"asymptotically correct\" z statistic is obtained as\n",
      "    # nobs/(1-np.sum(resols.params[1:-(trendorder+1)])) (resols.params[0] - 1)\n",
      "    # I think this is the statistic that is used for series that are integrated\n",
      "    # for orders higher than I(1), ie., not ADF but cointegration tests.\n",
      "\n",
      "    # Get approx p-value and critical values\n",
      "    pvalue = mackinnonp(adfstat, regression=regression, N=1)\n",
      "    critvalues = mackinnoncrit(N=1, regression=regression, nobs=nobs)\n",
      "    critvalues = {\"1%\" : critvalues[0], \"5%\" : critvalues[1],\n",
      "            \"10%\" : critvalues[2]}\n",
      "    if store:\n",
      "        resstore.ols = resols\n",
      "        resstore.usedlag = usedlag\n",
      "        resstore.nobs = nobs\n",
      "        return adfstat, pvalue, critvalues, resstore\n",
      "    else:\n",
      "        if not autolag:\n",
      "            return adfstat, pvalue, usedlag, nobs, critvalues\n",
      "        else:\n",
      "            return adfstat, pvalue, usedlag, nobs, critvalues, icbest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 478
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### Jenkins's method regression function. ####\n",
      "# Uses the ResultsStore class defined above to store results, but can also import it from statsmodels\n",
      "def jenkins_reg(dataframe, varlist, formula, LS = \"OLS\", weights = None):\n",
      "    # dataframe is a pd.DataFrame with all your observations\n",
      "    # varlist is a list of strings where the first string is the dependent variable and the second onwards are the independent variables\n",
      "    # formula is a string with your desired regression formula\n",
      "    # LS is a string that is either OLS or WLS, depending on the type of regression you want to do\n",
      "    # weights is optional and only required for WLS.\n",
      "    \n",
      "    print \"Please ensure that you have scaled your dataframes properly for your chosen method\"\n",
      "    \n",
      "    results = ResultsStore()\n",
      "    # Generating regression vars\n",
      "    \n",
      "    dictionary = {}\n",
      "    for v in varlist:\n",
      "        dictionary[v] = dataframe[v]\n",
      "    data = DataFrame(dictionary)\n",
      "\n",
      "    # Running Jenkins method regression\n",
      "\n",
      "    if LS == \"OLS\":\n",
      "        results.reg = smf.ols(formula = formula , data = data).fit()\n",
      "    \n",
      "    elif LS == \"WLS\":\n",
      "        results.reg = smf.wls(formula = formula, data = data, weights = weights).fit()\n",
      "    \n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 363
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is a list of acceptable countries for our analysis because we really don't want to include every minor country as that will\n",
      "# definitely ruin everything~~~~\n",
      "\n",
      "# European countries. Must be within mainland Europe.\n",
      "countries_european = [\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
      "                   \"Denmark\", \"Finland\", \"France\", \"Greece\", \"Hungary\", \"Iceland\", \"Italy\", \"Latvia\", \"Luxembourg\",\n",
      "                   \"Malta\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\",\n",
      "                   \"Spain\", \"Sweden\", \"Switzerland\", \"Ukraine\", \"United Kingdom\"]\n",
      "\n",
      "# Major countries. Excludes small islands, small nations, and most of the countries with serious turmoil.\n",
      "countries_major = [\"Algeria\", \"Australia\", \"Austria\", \"Belgium\", \"Brazil\", \"Bulgaria\", \"Canada\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
      "                   \"Denmark\", \"Finland\", \"France\", \"Greece\", \"Hungary\", \"Iceland\", \"Israel\", \"Italy\", \"Latvia\", \"Luxembourg\",\n",
      "                   \"Malta\", \"Mexico\", \"Morocco\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\",\n",
      "                   \"Saudi Arabia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Tunisia\", \"Ukraine\", \"United Kingdom\", \"United States\"]\n",
      "\n",
      "# Countries that we used in the Stata code\n",
      "countries_stata = [\"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", 'Czech Republic', 'Denmark', 'Finland', 'France',\n",
      "                   'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Latvia', 'Luxembourg', 'Malta', 'Netherlands',\n",
      "                   'Norway', 'Poland', 'Portugal', 'Romania', 'Spain', 'Sweden', 'Switzerland', 'United Kingdom']\n",
      "\n",
      "# Countries that are in Euro-West Asia-North Africa area\n",
      "countries_germanycen = [\"Algeria\", \"Austria\", \"Belgium\", \"Bulgaria\", \"Croatia\", \"Cyprus\", \"Czech Republic\",\n",
      "                   \"Denmark\", \"Finland\", \"France\", \"Greece\", \"Hungary\", \"Iceland\", \"Israel\", \"Italy\", \"Latvia\", \"Luxembourg\",\n",
      "                   \"Malta\", \"Morocco\", \"Netherlands\", \"Norway\", \"Poland\", \"Portugal\", \"Romania\", \"Russian Federation\",\n",
      "                   \"Saudi Arabia\", \"Spain\", \"Sweden\", \"Switzerland\", \"Tunisia\", \"Ukraine\", \"United Kingdom\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 365
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reading RER data (Change directory path for your needs)\n",
      "data_raw = pd.read_excel(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\Exchange Rate Data\\Data.xlsx\", sheet=\"DATA\",header=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Converting value column to floats\n",
      "data_raw[\"Value\"] = data_raw[\"Value\"].astype(float)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grabbing data for Real Exchange Rates by CPI\n",
      "RER_CPI_raw = data_raw[data_raw[\"Concept Code\"] == \"EREER\"]\n",
      "\n",
      "# Extracting only relevant columns\n",
      "l_col = [\"Country Label\", \"Country Code\", \"Time Code\", \"Value\"]\n",
      "\n",
      "RER_CPI = pd.DataFrame()\n",
      "for a in l_col:\n",
      "    RER_CPI[a] = RER_CPI_raw[a]\n",
      "\n",
      "# Converting time to date time\n",
      "RER_CPI[\"Time Code\"] = pd.to_datetime(data[\"Time Code\"],format=\"%YM%m\")\n",
      "\n",
      "# Converting value to log value\n",
      "RER_CPI[\"Log Value\"] = np.log(RER_CPI[\"Value\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Importing distance data\n",
      "distance = pd.read_excel(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\Country Distances (Deniz Ozensoy's conflicted copy 2015-03-04).xls\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 312
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Importing Balance of Trade data and cleaning it\n",
      "bal_trade = pd.read_csv(\"C:\\Users\\Allan Zhang\\Dropbox\\Research Project\\hpfilters.csv\")\n",
      "bal_trade = bal_trade.T\n",
      "bal_trade.columns = bal_trade.loc[\"Time\"]\n",
      "bal_trade = bal_trade[1:]\n",
      "\n",
      "# Arbitrarily removes any rows that have more than 50 nans.\n",
      "for c in bal_trade.index:\n",
      "    if sum(pd.isnull(bal_trade.loc[c])) > 50:\n",
      "        bal_trade = bal_trade.drop(c)\n",
      "\n",
      "# Gets average of remaining countries and stores them\n",
      "bal_trade_means = DataFrame({\"Mean\" : bal_trade.mean(1)})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 350
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Runs ADF for all countries and returns results in dictionary.\n",
      "# Results have format: { \"Country\" : [ OLS Coefficient, OLS Standard Error, # of lags ]}\n",
      "\n",
      "# Max lag = 2 chosen in the dataset to make it more comparable for our other results and because that's what we would want to estimate\n",
      "# in our model. An additional thing to try would be to use the autolag = \"t-stat\" command which searches for the first instance\n",
      "# of the lag where the tstat is significant. Unfortunately it breaks currently cuz the code is failing, but I can manually code it.\n",
      "# I know some paper uses it for max lag = 6. Don't remember which.\n",
      "results = {}\n",
      "for a in RER_CPI[\"Country Label\"].unique():\n",
      "    l = []\n",
      "    ad = adfuller_edit(RER_CPI[RER_CPI[\"Country Label\"] == a][\"Log Value\"], regression = 'ct', maxlag = 2, regresults = True)\n",
      "    l.append(ad[3].ols.params[0])\n",
      "    l.append(ad[3].ols.bse[0])\n",
      "    l.append(ad[3].usedlag)\n",
      "    results[a] = l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 471
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ad = adfuller_edit(RER_CPI[RER_CPI[\"Country Label\"] == a][\"Log Value\"], regression = 'ct', maxlag = 2, regresults = True)\n",
      "print ad[3].ols.summary()\n",
      "print ad[3].ols.conf_int(.05)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            OLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                      y   R-squared:                       0.099\n",
        "Model:                            OLS   Adj. R-squared:                  0.092\n",
        "Method:                 Least Squares   F-statistic:                     15.09\n",
        "Date:                Tue, 10 Mar 2015   Prob (F-statistic):           2.45e-09\n",
        "Time:                        13:20:36   Log-Likelihood:                 1136.3\n",
        "No. Observations:                 418   AIC:                            -2265.\n",
        "Df Residuals:                     414   BIC:                            -2248.\n",
        "Df Model:                           3                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "x1            -0.0217      0.008     -2.636      0.009        -0.038    -0.006\n",
        "x2             0.2971      0.047      6.348      0.000         0.205     0.389\n",
        "const          0.1015      0.039      2.608      0.009         0.025     0.178\n",
        "x3         -4.174e-06   6.97e-06     -0.599      0.549     -1.79e-05  9.52e-06\n",
        "==============================================================================\n",
        "Omnibus:                       59.126   Durbin-Watson:                   1.965\n",
        "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              392.523\n",
        "Skew:                          -0.341   Prob(JB):                     5.82e-86\n",
        "Kurtosis:                       7.698   Cond. No.                     1.45e+04\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "[2] The condition number is large, 1.45e+04. This might indicate that there are\n",
        "strong multicollinearity or other numerical problems.\n",
        "[[ -3.79376369e-02  -5.52526192e-03]\n",
        " [  2.05129769e-01   3.89163250e-01]\n",
        " [  2.49883288e-02   1.78040862e-01]\n",
        " [ -1.78690705e-05   9.52085381e-06]]\n"
       ]
      }
     ],
     "prompt_number": 484
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##### For outputting the ADF results. #####\n",
      "\n",
      "# Results have format: { \"Country\" : [ OLS Coefficient, OLS Standard Error, # of lags, ADF Test Statistic, MacKinnon's approximate p-value,\n",
      "# Observations count, 95% CI Lower, 95% CI Upper]}\n",
      "\n",
      "results_output = {}\n",
      "for a in RER_CPI[\"Country Label\"].unique():\n",
      "    l = []\n",
      "    ad = adfuller_edit(RER_CPI[RER_CPI[\"Country Label\"] == a][\"Log Value\"], regression = 'ct', maxlag = 2, regresults = True)\n",
      "    l.append(ad[3].ols.params[0])\n",
      "    l.append(ad[3].ols.bse[0])\n",
      "    l.append(ad[3].usedlag)\n",
      "    l.append(ad[0])\n",
      "    l.append(ad[1])\n",
      "    l.append(ad[3].nobs)\n",
      "    l.append(ad[3].ols.conf_int(.05)[0,0])\n",
      "    l.append(ad[3].ols.conf_int(.05)[0,1])\n",
      "    results_output[a] = l\n",
      "\n",
      "ADF_results = DataFrame(results_output)\n",
      "ADF_results = ADF_results.T\n",
      "ADF_results.columns = [\"Coefficient\", \"SE\", \"Used Lags\", \"ADF Statistic\", \"Approx p-value\", \"Observations\", \"95% CI Lower\", \"95% CI Upper\"]\n",
      "ADF_results = ADF_results.drop(\"Used Lags\", axis = 1)\n",
      "ADF_results[\"rho\"] = 1 + ADF_results[\"Coefficient\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 520
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "outliers = {}\n",
      "j = 0\n",
      "for i,r in ADF_results.iterrows():\n",
      "    if r[\"rho\"] < .9:\n",
      "        l = []\n",
      "        print j\n",
      "        print i,\n",
      "        print r[\"rho\"]\n",
      "        l.append(i)\n",
      "        l.append(r[\"rho\"])\n",
      "        outliers[j] = l\n",
      "    j = j +1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n",
        "Armenia, Republic of 0.890905509982\n",
        "8\n",
        "Belize 0.871950382751\n",
        "9\n",
        "Bolivia 0.867379606163\n",
        "11\n",
        "Bulgaria 0.871202994597\n",
        "49\n",
        "Latvia 0.885092104189\n",
        "52\n",
        "Macedonia, FYR 0.875099685821\n",
        "71\n",
        "Romania 0.830258394846\n",
        "90\n",
        "Ukraine 0.872972854948\n"
       ]
      }
     ],
     "prompt_number": 538
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### For plotting above ADF results. ###\n",
      "rhoplot = plt.plot(ADF_results[\"rho\"], 'x')\n",
      "plt.xlabel(\"Index\")\n",
      "plt.ylabel(\"rho\")\n",
      "plt.title(\"Estimated rho coefficients\")\n",
      "for k in outliers.keys():\n",
      "    if k == 11:\n",
      "        plt.annotate(outliers[k][0],\n",
      "             xy = (k,outliers[k][1]), xytext = (0,-90),\n",
      "             textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "             bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "             arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "    elif k == 9:\n",
      "        plt.annotate(outliers[k][0],\n",
      "             xy = (k,outliers[k][1]), xytext = (70,-90),\n",
      "             textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "             bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "             arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "    else:\n",
      "        plt.annotate(outliers[k][0],\n",
      "                     xy = (k,outliers[k][1]), xytext = (90,20),\n",
      "                     textcoords = 'offset points', ha = 'right', va = 'bottom',\n",
      "                     bbox = dict(boxstyle = 'round,pad=0.5', fc = 'yellow', alpha = 0.5),\n",
      "                     arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 554
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# l contains a list of countries that are exact matches between our distance and RER data\n",
      "l = []\n",
      "for i in results.keys():\n",
      "    for j in distance[\"Name\"]:\n",
      "        if i == j:\n",
      "            l.append(i)\n",
      "\n",
      "# prints a list of countries that are in RER data but not in distance. Highly likely most are due to names not being exact matches\n",
      "for i in results.keys():\n",
      "    if i not in l:\n",
      "        pass#print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 192
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates new data frame with the results from the ADF dictionary above\n",
      "jenkins = DataFrame(results)\n",
      "jenkins = jenkins.T\n",
      "jenkins.columns = [\"Coefficient\", \"SE\", \"Used Lags\"]\n",
      "\n",
      "# Merges data with distance based on intersection of country names and generates log distance\n",
      "jenkins = pd.merge(jenkins, distance, left_index = True, right_on = \"Name\")\n",
      "jenkins[\"log_dist\"] = np.log(jenkins[\"dist\"])\n",
      "\n",
      "# Generates the rho coefficients\n",
      "jenkins[\"rho\"] = 1 + jenkins[\"Coefficient\"]\n",
      "jenkins.columns\n",
      "\n",
      "# Deleting useless columns\n",
      "jenkins = jenkins.drop(['From', 'To', 'colony', 'comcol', 'curcol', 'col45', 'smctry'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 414
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Uses all countries in our data set\n",
      "weights = 1/(jenkins[\"SE\"]**2)\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist', data = jenkins, weights = weights).fit()\n",
      "print wls_results.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.038\n",
        "Model:                            WLS   Adj. R-squared:                  0.025\n",
        "Method:                 Least Squares   F-statistic:                     3.024\n",
        "Date:                Tue, 10 Mar 2015   Prob (F-statistic):             0.0860\n",
        "Time:                        12:33:38   Log-Likelihood:                 195.87\n",
        "No. Observations:                  79   AIC:                            -387.7\n",
        "Df Residuals:                      77   BIC:                            -383.0\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.9560      0.014     67.013      0.000         0.928     0.984\n",
        "log_dist       0.0030      0.002      1.739      0.086        -0.000     0.006\n",
        "==============================================================================\n",
        "Omnibus:                        8.597   Durbin-Watson:                   1.676\n",
        "Prob(Omnibus):                  0.014   Jarque-Bera (JB):                8.218\n",
        "Skew:                          -0.681   Prob(JB):                       0.0164\n",
        "Kurtosis:                       3.801   Cond. No.                         59.8\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      }
     ],
     "prompt_number": 459
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Examines a subset of the data where countries are on the same continent as Germany\n",
      "jenkins_germanycen = jenkins.loc[jenkins[\"Name\"].isin(countries_germanycen)]\n",
      "\n",
      "weights = 1/(jenkins_germanycen[\"SE\"]**2)\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist', data = jenkins_germanycen, weights = weights).fit()\n",
      "print wls_results.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.105\n",
        "Model:                            WLS   Adj. R-squared:                  0.075\n",
        "Method:                 Least Squares   F-statistic:                     3.515\n",
        "Date:                Tue, 10 Mar 2015   Prob (F-statistic):             0.0706\n",
        "Time:                        12:28:44   Log-Likelihood:                 76.517\n",
        "No. Observations:                  32   AIC:                            -149.0\n",
        "Df Residuals:                      30   BIC:                            -146.1\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.9260      0.028     32.877      0.000         0.869     0.984\n",
        "log_dist       0.0074      0.004      1.875      0.071        -0.001     0.015\n",
        "==============================================================================\n",
        "Omnibus:                        3.978   Durbin-Watson:                   2.030\n",
        "Prob(Omnibus):                  0.137   Jarque-Bera (JB):                2.778\n",
        "Skew:                          -0.705   Prob(JB):                        0.249\n",
        "Kurtosis:                       3.311   Cond. No.                         61.6\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
       ]
      }
     ],
     "prompt_number": 458
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Examines a subset of the data where countries are the same as in the Stata Regression\n",
      "jenkins_stata = jenkins.loc[jenkins[\"Name\"].isin(countries_Stata)]\n",
      "\n",
      "# Generating weighted variables for Jenkins's specification of his regression\n",
      "jenkins_stata[\"rho_ols\"] = jenkins_stata[\"rho\"]/jenkins_stata[\"SE\"]\n",
      "jenkins_stata[\"log_dist_ols\"] = jenkins_stata[\"log_dist\"]/jenkins_stata[\"SE\"]\n",
      "\n",
      "weights = 1/(jenkins_stata[\"SE\"]**2)\n",
      "\n",
      "# Running Jenkins method regression\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist', data = jenkins_stata, weights = weights).fit()\n",
      "#ols_results = smf.ols(formula = 'rho_ols ~ log_dist_ols' , data = jenkins_stata).fit()\n",
      "print wls_results.summary()\n",
      "print ols_results.params\n",
      "print ols_results.conf_int(.05)\n",
      "\n",
      "#data_OLS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.034\n",
        "Model:                            WLS   Adj. R-squared:                 -0.006\n",
        "Method:                 Least Squares   F-statistic:                    0.8495\n",
        "Date:                Tue, 10 Mar 2015   Prob (F-statistic):              0.366\n",
        "Time:                        12:44:07   Log-Likelihood:                 63.546\n",
        "No. Observations:                  26   AIC:                            -123.1\n",
        "Df Residuals:                      24   BIC:                            -120.6\n",
        "Df Model:                           1                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.9443      0.033     28.909      0.000         0.877     1.012\n",
        "log_dist       0.0044      0.005      0.922      0.366        -0.005     0.014\n",
        "==============================================================================\n",
        "Omnibus:                        8.170   Durbin-Watson:                   2.297\n",
        "Prob(Omnibus):                  0.017   Jarque-Bera (JB):                6.149\n",
        "Skew:                          -1.038   Prob(JB):                       0.0462\n",
        "Kurtosis:                       4.170   Cond. No.                         60.5\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "Intercept             19.035178\n",
        "log_dist_ols           0.104524\n",
        "bal_trade_mean_ols     0.767127\n",
        "dtype: float64\n",
        "                           0          1\n",
        "Intercept           3.910846  34.159510\n",
        "log_dist_ols        0.084516   0.124532\n",
        "bal_trade_mean_ols  0.241856   1.292398\n"
       ]
      }
     ],
     "prompt_number": 461
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Integrating the balance of trade data into Jenkins regression\n",
      "jenkins_baltrade = pd.merge(jenkins, bal_trade_means, left_on = \"Name\", right_index = True)\n",
      "\n",
      "# Generating regression vars\n",
      "\n",
      "jenkins_baltrade[\"rho_ols\"] = jenkins_baltrade[\"rho\"]/jenkins_baltrade[\"SE\"]\n",
      "jenkins_baltrade[\"log_dist_ols\"] = jenkins_baltrade[\"log_dist\"]/jenkins_baltrade[\"SE\"]\n",
      "jenkins_baltrade[\"bal_trade_mean_ols\"] = jenkins_baltrade[\"Mean\"]/jenkins_baltrade[\"SE\"]\n",
      "\n",
      "weights = 1/(jenkins_baltrade[\"SE\"]**2)\n",
      "\n",
      "# Running Jenkins method regression\n",
      "\n",
      "wls_results = smf.wls(formula = 'rho ~ log_dist + Mean', data = jenkins_baltrade, weights = weights).fit()\n",
      "#ols_results = smf.ols(formula = 'rho_ols ~ log_dist_ols + bal_trade_mean_ols' , data = jenkins_baltrade).fit()\n",
      "print wls_results.summary()\n",
      "print wls_results.params[\"log_dist\"]\n",
      "print wls_results.conf_int(.05)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                            WLS Regression Results                            \n",
        "==============================================================================\n",
        "Dep. Variable:                    rho   R-squared:                       0.490\n",
        "Model:                            WLS   Adj. R-squared:                  0.411\n",
        "Method:                 Least Squares   F-statistic:                     6.239\n",
        "Date:                Wed, 11 Mar 2015   Prob (F-statistic):             0.0126\n",
        "Time:                        04:54:50   Log-Likelihood:                 54.067\n",
        "No. Observations:                  16   AIC:                            -102.1\n",
        "Df Residuals:                      13   BIC:                            -99.82\n",
        "Df Model:                           2                                         \n",
        "Covariance Type:            nonrobust                                         \n",
        "==============================================================================\n",
        "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
        "------------------------------------------------------------------------------\n",
        "Intercept      0.8852      0.027     33.205      0.000         0.828     0.943\n",
        "log_dist       0.0119      0.004      3.385      0.005         0.004     0.019\n",
        "Mean           0.0882      0.039      2.282      0.040         0.005     0.172\n",
        "==============================================================================\n",
        "Omnibus:                        2.924   Durbin-Watson:                   1.674\n",
        "Prob(Omnibus):                  0.232   Jarque-Bera (JB):                1.147\n",
        "Skew:                          -0.083   Prob(JB):                        0.564\n",
        "Kurtosis:                       1.699   Cond. No.                         138.\n",
        "==============================================================================\n",
        "\n",
        "Warnings:\n",
        "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
        "0.0118824965573"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                  0         1\n",
        "Intercept  0.827566  0.942746\n",
        "log_dist   0.004298  0.019467\n",
        "Mean       0.004717  0.171769\n"
       ]
      }
     ],
     "prompt_number": 556
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Generating plot of distance versus estimated effect of distance on rho ###\n",
      "def plot_rho_dist(data, wls_results):\n",
      "    plt.plot(np.exp(data[\"log_dist\"]),data[\"log_dist\"]*wls_results.params[\"log_dist\"], 'x')\n",
      "    \n",
      "plot_rho_dist(jenkins_baltrade, wls_results)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 562
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets a list of countries for which we have less than a certain number of data points\n",
      "for a in RER_CPI[\"Country Label\"].unique():\n",
      "    if RER_CPI[RER_CPI[\"Country Label\"] == str(a)][\"Time Code\"].min() > pd.Timestamp('19790101'):\n",
      "        pass\n",
      "#         print a\n",
      "#         print RER_CPI[RER_CPI[\"Country Label\"] == str(a)][\"Time Code\"].min()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 239
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Super hackish way to get google docs to format stuff nicely.\n",
      "str = \"\"\"Country\tADF Statistic\tp-value\trho\tStd. Err.\tt\tP>| t |\t95% CIL\t95% CIU\n",
      "Austria\t-3.352\t0.0581\t0.9749732\t0.0074661\t-3.35\t0.001\t0.9602981\t0.9896482\n",
      "Belgium\t-2.473\t0.3417\t0.9803126\t0.0079615\t-2.47\t0.014\t0.9646638\t0.9959615\n",
      "Bulgaria\t-4.206\t0.0044\t0.9030904\t0.0230392\t-4021\t0\t0.8577304\t0.9484504\n",
      "Croatia\t-2.923\t0.1549\t0.9499666\t0.0171169\t-2.92\t0.004\t0.9162647\t0.9836685\n",
      "Cyprus\t-1.369\t0.8699\t0.9902017\t0.0071586\t-1.37\t0.172\t0.9761297\t1.0042736\n",
      "Czech Republic\t-2.527\t0.3147\t0.9466014\t0.0211333\t-2.53\t0.012\t0.905009\t0.9881938\n",
      "Denmark\t-2.394\t0.3828\t0.976163\t0.0099572\t-2.39\t0.017\t0.9565915\t0.957344\n",
      "Finland\t-2.538\t0.3903\t0.9775861\t0.0092781\t-2.21\t0.016\t0.9593481\t0.9958241\n",
      "France\t-2.419\t0.3713\t0.9775861\t0.0092781\t-2.42\t0.016\t0.9593481\t0.9958241\n",
      "Greece\t-2.879\t0.1695\t0.9642326\t0.0124237\t-2.88\t0.004\t0.9398111\t0.9886542\n",
      "Hungary\t-2.407\t0.3757\t0.9772322\t0.0094575\t-2.41\t0.017\t0.9586414\t0.995823\n",
      "Iceland\t-3.284\t0.069\t0.9649166\t0.0106846\t-3.28\t0.001\t0.9439153\t0.9859179\n",
      "Ireland\t-2.829\t0.1863\t0.9838948\t0.005692\t-2.83\t0.005\t0.9727068\t0.9950829\n",
      "Italy\t-2.41\t0.3745\t0.9831155\t0.0070068\t-2.41\t0.016\t0.9693421\t0.9968889\n",
      "Lativa\t-3.566\t0.0328\t0.9454487\t0.0152976\t-3.57\t0\t0.9153304\t0.975567\n",
      "Luxemburg\t-2.443\t0.357\t0.9782142\t0.0089178\t-2.44\t0.015\t0.9606857\t0.9957428\n",
      "Malta\t-1.065\t0.9347\t0.994958\t0.0047349\t-1.06\t0.288\t0.9856513\t1.0042647\n",
      "Norway\t-1.451\t0.8454\t0.9928809\t0.004907\t-1.45\t0.148\t0.9832358\t1.002526\n",
      "Netherlands\t-2.612\t0.2746\t0.9772406\t0.0087149\t-2.61\t0.009\t0.9601109\t0.9943703\n",
      "Poland\t-3.94\t0.0107\t0.9446897\t0.0140371\t-3.94\t0.001\t0.9170721\t0.9723073\n",
      "Portugal\t-3.522\t0.0371\t0.9619046\t0.0108179\t-3.52\t0\t0.9406414\t0.9831678\n",
      "Romania\t-4.332\t0.0028\t0.8684964\t0.030542\t-4.33\t0\t0.8087485\t0.9282442\n",
      "Slovak Republic\t-3.189\t0.0867\t0.958842\t0.012907\t-3.19\t0.002\t0.9334397\t0.9842442\n",
      "Spain\t-1.98\t0.6121\t0.985733\t0.0072043\t-1.98\t0.048\t0.9715714\t0.9998946\n",
      "Sweden\t-3.292\t0.0371\t0.965096\t0.010602\t-3.29\t0.001\t0.9442572\t0.9859349\n",
      "Switzerland\t-2.495\t0.0028\t0.8684964\t0.030542\t-4.33\t0.013\t0.8087485\t0.9282442\n",
      "United Kingdom\t-3.696\t0.0226\t0.9665722\t0.0090443\t-3.7\t0\t0.9487951\t0.9843493\n",
      "\n",
      "\"\"\"\n",
      "print str.expandtabs(15)\n",
      "# with open('ADF2.txt', 'wb') as file:\n",
      "#     file.write(str.expandtabs(25))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Country        ADF Statistic  p-value        rho            Std. Err.      t              P>| t |        95% CIL        95% CIU\n",
        "Austria        -3.352         0.0581         0.9749732      0.0074661      -3.35          0.001          0.9602981      0.9896482\n",
        "Belgium        -2.473         0.3417         0.9803126      0.0079615      -2.47          0.014          0.9646638      0.9959615\n",
        "Bulgaria       -4.206         0.0044         0.9030904      0.0230392      -4021          0              0.8577304      0.9484504\n",
        "Croatia        -2.923         0.1549         0.9499666      0.0171169      -2.92          0.004          0.9162647      0.9836685\n",
        "Cyprus         -1.369         0.8699         0.9902017      0.0071586      -1.37          0.172          0.9761297      1.0042736\n",
        "Czech Republic -2.527         0.3147         0.9466014      0.0211333      -2.53          0.012          0.905009       0.9881938\n",
        "Denmark        -2.394         0.3828         0.976163       0.0099572      -2.39          0.017          0.9565915      0.957344\n",
        "Finland        -2.538         0.3903         0.9775861      0.0092781      -2.21          0.016          0.9593481      0.9958241\n",
        "France         -2.419         0.3713         0.9775861      0.0092781      -2.42          0.016          0.9593481      0.9958241\n",
        "Greece         -2.879         0.1695         0.9642326      0.0124237      -2.88          0.004          0.9398111      0.9886542\n",
        "Hungary        -2.407         0.3757         0.9772322      0.0094575      -2.41          0.017          0.9586414      0.995823\n",
        "Iceland        -3.284         0.069          0.9649166      0.0106846      -3.28          0.001          0.9439153      0.9859179\n",
        "Ireland        -2.829         0.1863         0.9838948      0.005692       -2.83          0.005          0.9727068      0.9950829\n",
        "Italy          -2.41          0.3745         0.9831155      0.0070068      -2.41          0.016          0.9693421      0.9968889\n",
        "Lativa         -3.566         0.0328         0.9454487      0.0152976      -3.57          0              0.9153304      0.975567\n",
        "Luxemburg      -2.443         0.357          0.9782142      0.0089178      -2.44          0.015          0.9606857      0.9957428\n",
        "Malta          -1.065         0.9347         0.994958       0.0047349      -1.06          0.288          0.9856513      1.0042647\n",
        "Norway         -1.451         0.8454         0.9928809      0.004907       -1.45          0.148          0.9832358      1.002526\n",
        "Netherlands    -2.612         0.2746         0.9772406      0.0087149      -2.61          0.009          0.9601109      0.9943703\n",
        "Poland         -3.94          0.0107         0.9446897      0.0140371      -3.94          0.001          0.9170721      0.9723073\n",
        "Portugal       -3.522         0.0371         0.9619046      0.0108179      -3.52          0              0.9406414      0.9831678\n",
        "Romania        -4.332         0.0028         0.8684964      0.030542       -4.33          0              0.8087485      0.9282442\n",
        "Slovak Republic               -3.189         0.0867         0.958842       0.012907       -3.19          0.002          0.9334397      0.9842442\n",
        "Spain          -1.98          0.6121         0.985733       0.0072043      -1.98          0.048          0.9715714      0.9998946\n",
        "Sweden         -3.292         0.0371         0.965096       0.010602       -3.29          0.001          0.9442572      0.9859349\n",
        "Switzerland    -2.495         0.0028         0.8684964      0.030542       -4.33          0.013          0.8087485      0.9282442\n",
        "United Kingdom -3.696         0.0226         0.9665722      0.0090443      -3.7           0              0.9487951      0.9843493\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 519
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Last cell reserved for outputting results to a csv\n",
      "# with open('Results.csv', 'wb') as csvfile:\n",
      "#     writer = csv.writer(csvfile)\n",
      "#     for r in RER_CPI[RER_CPI[\"Country Label\"] == \"France\"][\"Log Value\"]:\n",
      "#         writer.writerow([r])\n",
      "\n",
      "jenkins.to_csv(\"Results_Jenkins.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 216
    }
   ],
   "metadata": {}
  }
 ]
}